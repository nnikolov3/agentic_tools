# =============================================================================
# FILE PROCESSING RULES (For ShellTools/FileBrowser)
# =============================================================================
[file_processing]
# Extensions to include during directory scans (e.g., for ingest_knowledge_bank.py)
include_extensions = [".go", ".py", ".md", ".toml", ".json", ".txt", ".yaml"]
# Files to exclude explicitly
exclude_files = ["__init__.py", ".env", "secrets.py"]
# Directories to skip (safety: avoids git noise, venvs, builds)
exclude_directories = [
    ".git",
    ".github",
    ".idea",
    "__pycache__",
    "venv",
    ".venv",
    "dist",
    "build",
    "target",
    ".mypy_cache",
    "node_modules"
]
# Max file size for processing (25 MiB; prevents large binaries)
max_file_bytes = 26214400

# Git ops defaults (used in ShellTools for get_git_context_for_patch)
git_diff_command = ["diff", "HEAD", "--patch-with-raw", "--minimal", "--patience", ":!uv.lock", ":!MANIFEST.in"]
git_log_command = ["log", "--pretty=format:%h %s %an %ar", "-n"]
commit_number = 3  # Recent commits for context
tree_depth = 3     # Directory tree depth in get_project_tree

# =============================================================================
# TOOLS CONFIGURATION (For tool.py Registry: CodeInterpreter, FileBrowser, WebSearch, etc.)
# =============================================================================
[tools]
# Global tool settings
timeout = 30  # Default subprocess/await timeout (seconds)
temp_base = "/tmp/agentic"  # Base for temp dirs (CodeInterpreter cleans up via atexit)

# CodeInterpreter: Multi-lang safe executor (Python ast-safe, Go/C compile-run, Bash restricted)
[code_interpreter]
supported_langs = ["python", "go", "c", "bash"]  # From payload["language"]
timeout = 5  # Per-lang execution timeout
temp_base = "/tmp/agentic"  # Temp files for Go/C/Bash compiles
allowed_commands = ["go", "gcc", "bash"]  # Restrict subprocess (no rm/mkfs/dd)
unsafe_patterns = ["rm -rf", "dd if=", "mkfs"]  # Bash safety scan

# FileBrowser: Pathlib-based async walker (no shell; uses config exclusions)
[file_browser]
max_depth = 3  # Recursion limit (avoids deep nests)
include_extensions = [".py", ".go", ".md", ".toml"]  # Override [file_processing] if needed

# WebSearch: Async DDGS (DuckDuckGo; filters ads, caps results)
[web_search]
max_results = 10  # Default; cap at 20 in execute for rate-limits
proxy = ""  # Optional: "http://your-vm-proxy:port" for VM firewall

# ShellTools: Wrapper for git/file ops (aliases git_ops to shell_exec)
[shell_exec]
allowed_commands = ["git", "tree", "sync"]  # Explicit allow-list (safety)
allowed_patterns = ["git diff", "git log", "tree -L"]  # No destructive cmds

# API Tools (Mistral fallback for api_call/mistral_chat/embed)
[api_call]
model = "mistral-large-latest"  # Or "openai/gpt-4o" if keys set
api_key_env = "MISTRAL_API_KEY"  # Load from os.getenv
max_tokens = 4096
temperature = 0.3

# =============================================================================
# MEMORY & QDRANT CONFIGURATION (For qdrant_memory.py / QdrantClientManager)
# =============================================================================
[memory]
enabled = true
collection_name = "agent_memory"  # Agent-specific memories
knowledge_bank_collection_name = "knowledge-bank"  # Global KB (ingest_knowledge_bank.py)
embedding_model = { provider = "google", model = "gemini-embedding-001" }  # Google Gemini Embedding
embedding_size = 3072  # Gemini embedding-001 default dim
sparse_embedding_model = "prithivida/Splade_PP_en_v1"  # For hybrid search
qdrant_url = "http://192.168.122.40:6333"  # Your KVM VM (gRPC:6334 if prefer_grpc=true)
timeout = 60  # Connection timeout
prefer_grpc = true  # For faster async (ports 6334/6335 forwarded)
api_key = ""  # None for local VM
device = "cpu"  # Fallback to cuda if torch.cuda.is_available()
total_memories_to_retrieve = 20  # Total from all time buckets
query_points_hnsw_ef = 128  # HNSW search param (balance speed/accuracy)

# Time-decay retrieval weights (0.0 for fresh focus; knowledge_bank=1.0 heavy)
hourly_retrieval_weight = 0.0
daily_retrieval_weight = 0.0
weekly_retrieval_weight = 0.0
two_weeks_retrieval_weight = 0.0
monthly_retrieval_weight = 0.0
ninety_days_retrieval_weight = 0.0
one_eighty_days_retrieval_weight = 0.0
three_sixty_days_retrieval_weight = 0.0
knowledge_bank_retrieval_weight = 1.0

# Pruning settings
prune_enabled = true
prune_days = 365
prune_confidence_threshold = 0.0
prune_batch_size = 100

# Priority scoring parameters
priority_recency_weight = 0.3
priority_frequency_weight = 0.2
priority_importance_weight = 0.5
frequency_max_accesses = 100
recency_half_life_days = 30.0

[knowledge_bank_ingestion]
embedding_size = 3072
source_directory = "docs/knowledge"
output_directory = ".ingested"
supported_extensions = [".json", ".md", ".pdf"]
chunk_size = 1024
chunk_overlap = 256
qdrant_batch_size = 128
concurrency_limit = 2
prompt = "Summarize this document with practical examples."
model = "gemini-2.0-flash-exp"
google_api_key_name = "GEMINI_API_KEY"

[tools.qdrant]
vectors_config = { size = 3072, distance = "COSINE", on_disk = true }
sparse_vectors_config = { text-sparse = { index = {}, modifier = "NONE" } }
hnsw_config = { m = 32, ef_construct = 400, max_indexing_threads = -1, on_disk = true }  # -1 = cpu_count()
optimizers_config = { max_optimization_threads = -1, indexing_threshold = 20000 }
wal_config = { wal_capacity_mb = 1024, wal_segment_size_mb = 256 }
quantization_config = { type = "int8", quantile = 0.99, always_ram = false }

# Payload indexes for memory points (timestamp, text_content, etc.)
payload_indexes = [
    { field_name = "timestamp", field_schema = "keyword" },
    { field_name = "text_content", field_schema = "text" },
    { field_name = "day_of_week", field_schema = "keyword" }
]

# Reranker (fastembed; disabled if no GPU)
[reranker]
enabled = true
model_name = "jinaai/jina-reranker-v2-base-multilingual"
device = "cpu"

# =============================================================================
# AGENT CONFIGURATIONS (For agent.py / MCP Multi-Agent Flow)
# =============================================================================
[agentic-tools]
default_temperature = 0.3
default_device = "cpu"
design_docs = ["DESIGN_PRINCIPLES_GUIDE.md", "PYTHON_CODING_STANDARDS.md"]  # For get_design_docs_content
project_directories = ["src", "tests", "docs"]  # For process_directory scans
encoding = "utf-8"

[agents]
# Developer: Refactors single files with latest libs (e.g., ddgs, async)
[agents.developer]
name = "developer"
temperature = 0.2
skills = ["expert python/go developer", "async patterns", "debugging", "mypy/ruff/black compliance", "problem decomposition"]
prompt = '''
You are the 'developer', an expert async Python/Go engineer for MCP agents.
Refactor/optimize the given file using latest libs (e.g., ddgs for search, aiofiles for I/O).
Adhere to Design Principles: Explicit > Implicit, Simple > Complex, DRY/KISS.
Output ONLY the complete fileâ€”no explanations.
'''

# Architect: Plans system (e.g., Qdrant + multi-agent)
[agents.architect]
name = "architect"
temperature = 0.3
skills = ["system design", "vector DB integration", "MCP protocols", "scalability"]
prompt = '''
You are a senior Architect for AI/multi-agent systems (Qdrant, Mistral, async tools).
Create detailed architecture/plans for the problem, following Golden Rules.
Include diagrams in Markdown, focus on modularity.
'''

# Approver: Reviews diffs (JSON output for automation)
[agents.approver]
name = "approver"
temperature = 0.1
skills = ["code review", "standards enforcement", "risk assessment"]
prompt = '''
Senior engineer: Review git diff against principles/standards.
Output ONLY JSON: {"decision": "APPROVED|CHANGES_REQUESTED", "summary": "...", "positive_points": [...], "negative_points": [...], "required_actions": [...], "commit_message_if_approved": "..."}
'''

# Readme Writer: Generates README from context
[agents.readme_writer]
name = "readme_writer"
temperature = 0.3
skills = ["technical docs", "structure", "examples"]
prompt = '''
Expert writer: Create/update README.md from code/context.
Sections: Title/Desc, Features, Prereqs, Install, Usage, Config.
Output ONLY the full README.md content.
'''

# Expert: Summarizes docs for KB ingestion
[agents.expert]
name = "expert"
temperature = 0.3
skills = ["summarization", "examples", "tagging"]
prompt = '''
Technical expert: Summarize doc for vector KB.
JSON: {"title": "...", "short_summary": "...", "content": "(detailed w/ examples)", "tags": [...], "practical_examples": [...]}
'''

# Linter Analyst: Analyzes raw linter output (no fixes)
[linter_analyst]
name = "linter_analyst"
temperature = 0.2
skills = ["static analysis", "prioritization", "impact assessment"]
prompt = '''
Architect as linter analyst: Analyze mypy/ruff/golangci output vs. principles.
Markdown report: Group issues, explain WHY/HOW to fix, prioritize (maintainability > style).
No code changes.
'''

# =============================================================================
# LINTER CONFIGURATION (For run_project_linters in ShellTools)
# =============================================================================
[linters]
# Python: mypy (types), ruff (lint/style), black (format)
python = ["mypy src --config-file pyproject.toml", "ruff check src --fix", "black src --check"]
# Go: golangci-lint (comprehensive)
go = ["golangci-lint run ./src/..."]

# =============================================================================
# GOLDEN RULES & STANDARDS (Loaded in Prompts for All Agents)
# =============================================================================
[golden_rules]
rules = '''
1. Write what you mean, mean what you write. (Explicit intent)
2. Smaller is faster. (Concise code/functions)
3. Simple is efficient. (KISS: Avoid over-engineering)
4. Explicit > Implicit. (No magic; document assumptions)
5. Use whole words. (Clear variable/names: e.g., user_name not un)
6. Related code lives together. (Modular, co-located)
7. No hard-coded values. (Use config/env)
8. Fresh info/specs. (Latest libs: ddgs 0.7+, Qdrant 1.10+)
9. Clean trash code. (Refactor on sight; no dead vars)
10. Read problem 3x. (Understand before code)
11. Plan first. (Architecture before implementation)
12. DRY: Don't Repeat Yourself.
13. KISS: Keep It Simple, Stupid.
14. Accurate comments. (Explain WHY, not WHAT)
15. Put love and care in your work. This is a craft.
16. Making baseless assumptions is guessing, and guessing is like the lottery.
17. If you don't know, ask someone who does know.
18. Set the expectations early.
'''

# =============================================================================
# MCP / MULTI-AGENT FLOW (For main.py / agent.py)
# =============================================================================
[mcp]
providers = ["mistral", "openai", "groq"]  # API keys from env
agent_sequence = ["architect", "developer", "linter_analyst", "approver", "readme_writer"]  # Workflow order
max_iterations = 5  # Loop until approved
log_level = "DEBUG"  # For logger in tool.py/shell_tools.py

# =============================================================================
# TEST CONFIGURATION (For test_qdrant_write.py)
# =============================================================================
[test]
collection_name = "agent_memory_test_new"
knowledge_bank_collection_name = "knowledge_bank_test"
embedding_model = { provider = "google", model = "gemini-embedding-001", embedding_size = 3072 }
hourly_retrieval_weight = 0.8
daily_retrieval_weight = 0.0
knowledge_bank_retrieval_weight = 0.2

