
# /home/nnikolov3/multi-agent-mcp/config.yaml
project:
  name: "Multi-Agent Development Team"
  version: "4.0.0"
  author: "Nikolay Nikolov"

logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "multi_agent_dev_team.log"

qdrant:
  url: "${QDRANT_URL}"
  api_key: "${QDRANT_API_KEY}"
  collections:
    - "tasks"
    - "architectures"
    - "implementations"
    - "code_reviews"
    - "test_strategies"
    - "security_findings"
    - "diagrams"
    - "documentation"
    - "git_commits"
    - "ci_cd_configs"
    - "llm_cache"
    - "feedback"
    - "context_memory"
    - "optimization_patterns"
    - "groq_workflows"
    - "conversations"
    - "success_logs"
    - "failure_logs"
    - "learning_patterns"
    - "performance_metrics"
    - "project_files"
    - "chats"
    - "chat_threads"
    - "chat_feedback"
    - "chat_analytics"
    - "agent_memory"

context_retrieval:
  collections:
    - "project_files"
    - "implementations"
    - "success_logs"
    - "failure_logs"
    - "conversations"
    - "learning_patterns"
  limit_per_collection: 2


auth:
  roles:
    admin:
      - "call_leadership"
      - "call_development"
      - "call_qa"
      - "call_docs"
      - "call_devops"
      - "view_tasks"
      - "create_tasks"
      - "delete_tasks"
      - "view_analytics"
      - "manage_users"
    developer:
      - "call_development"
      - "call_qa"
      - "call_docs"
      - "view_tasks"
      - "create_tasks"
      - "view_analytics"
    tester:
      - "call_qa"
      - "view_tasks"
      - "view_analytics"
    writer:
      - "call_docs"
      - "view_tasks"
    viewer:
      - "view_tasks"
      - "view_analytics"

  agent_permissions:
    call_leadership: ["tech_lead", "architect"]
    call_development: [
        "gpt5_flagship", "gpt5_mini", "gpt5_nano", "gpt41_smart", "o3_researcher",
        "o4_mini_researcher", "gpt_oss_120b", "groq_compound", "groq_compound_mini",
        "llama4_maverick", "llama4_scout", "llama33_versatile", "kimi_256k",
        "cerebras_llama4_scout", "cerebras_llama4_maverick", "cerebras_qwen3_235b",
        "cerebras_qwen3_coder", "qwen_max", "qwen_plus", "qwen_coder_480b", "qwq_reasoning",
        "gemini_pro", "gemini_flash", "gemini_flash_lite"
    ]
    call_qa: ["qa_engineer", "security_auditor"]
    call_docs: ["technical_writer", "diagram_specialist"]
    call_devops: ["git_specialist", "devops_engineer"]

providers:
  openai:
    api_key: "${OPENAI_API_KEY}"
  groq:
    api_key: "${GROQ_API_KEY}"
  google:
    api_key: "${GOOGLE_API_KEY}"
  gemini:
    api_key: "${GEMINI_API_KEY}"
  cerebras:
    personal_key: "${CEREBRAS_API_KEY_PERSONAL}"
    book_expert_key: "${CEREBRAS_API_KEY_BOOK_EXPERT}"
  dashscope:
    api_key: "${DASHSCOPE_API_KEY}"

agents:
  gpt5_flagship: { model: "gpt-5", provider: "openai", role: "Flagship GPT-5", temp: 0.3, tokens: 16000 }
  gpt5_mini: { model: "gpt-5-mini", provider: "openai", role: "Fast GPT-5", temp: 0.3, tokens: 12000 }
  gpt5_nano: { model: "gpt-5-nano", provider: "openai", role: "Fastest GPT-5", temp: 0.4, tokens: 8000 }
  gpt41_smart: { model: "gpt-4.1", provider: "openai", role: "Smartest non-reasoning", temp: 0.2, tokens: 12000 }
  o3_researcher: { model: "o3-deep-research", provider: "openai", role: "Deep research", temp: 0.1, tokens: 16000 }
  o4_mini_researcher: { model: "o4-mini-deep-research", provider: "openai", role: "Fast research", temp: 0.2, tokens: 12000 }
  gpt_oss_120b: { model: "gpt-oss-120b", provider: "openai", role: "Open-weight 120B", temp: 0.3, tokens: 12000 }
  groq_compound: { model: "groq/compound", provider: "groq", role: "Compound system", temp: 0.5, tokens: 12000 }
  groq_compound_mini: { model: "groq/compound-mini", provider: "groq", role: "Fast compound", temp: 0.5, tokens: 8000 }
  groq_gpt_oss: { model: "openai/gpt-oss-120b", provider: "groq", role: "GPT-OSS on Groq", temp: 0.3, tokens: 12000 }
  llama4_maverick: { model: "meta-llama/llama-4-maverick-17b-128e-instruct", provider: "groq", role: "Llama 4 heavy", temp: 0.4, tokens: 10000 }
  llama4_scout: { model: "meta-llama/llama-4-scout-17b-16e-instruct", provider: "groq", role: "Llama 4 planning", temp: 0.4, tokens: 10000 }
  llama33_versatile: { model: "llama-3.3-70b-versatile", provider: "groq", role: "Llama 3.3 70B", temp: 0.4, tokens: 12000 }
  kimi_256k: { model: "moonshotai/kimi-k2-instruct-0905", provider: "groq", role: "256k context", temp: 0.4, tokens: 16000 }
  groq_qwen: { model: "qwen/qwen3-32b", provider: "groq", role: "Qwen 3 on Groq", temp: 0.3, tokens: 8000 }
  gemini_pro: { model: "gemini-2.5-pro", provider: "google_stable", role: "Gemini Pro", temp: 0.2, tokens: 16000 }
  gemini_flash: { model: "gemini-2.5-flash", provider: "google_stable", role: "Gemini Flash", temp: 0.3, tokens: 16000 }
  gemini_flash_lite: { model: "gemini-2.5-flash-lite", provider: "google_stable", role: "Ultra-fast", temp: 0.3, tokens: 12000 }
  qa_engineer: { model: "gemini-2.5-flash", provider: "google_stable", role: "QA Testing", temp: 0.2, tokens: 8000 }
  security_auditor: { model: "gemini-2.5-flash", provider: "google_stable", role: "Security", temp: 0.2, tokens: 8000 }
  technical_writer: { model: "gemini-2.5-pro", provider: "google_stable", role: "Documentation", temp: 0.3, tokens: 12000 }
  git_specialist: { model: "gemini-2.5-flash-lite", provider: "google_stable", role: "Git", temp: 0.2, tokens: 4000 }
  devops_engineer: { model: "gemini-2.5-flash", provider: "google_stable", role: "CI/CD", temp: 0.2, tokens: 8000 }
  cerebras_llama4_scout: { model: "llama-4-scout-17b-16e-instruct", provider: "cerebras", fallback: "groq", role: "Cerebras Llama 4 Scout", temp: 0.4, tokens: 10000 }
  cerebras_llama4_maverick: { model: "llama-4-maverick-17b-128e-instruct", provider: "cerebras", fallback: "groq", role: "Cerebras Llama 4 Maverick", temp: 0.4, tokens: 12000 }
  cerebras_qwen3_235b: { model: "qwen-3-235b-a22b-instruct-2507", provider: "cerebras", fallback: "groq", fallback_model: "qwen/qwen3-32b", role: "Qwen 3 235B", temp: 0.3, tokens: 16000 }
  cerebras_qwen3_coder: { model: "qwen-3-coder-480b", provider: "cerebras", fallback: "groq", fallback_model: "qwen/qwen3-32b", role: "Qwen 3 Coder 480B", temp: 0.3, tokens: 16000 }
  qwen_max: { model: "qwen-max", provider: "qwen", fallback: "groq", fallback_model: "qwen/qwen3-32b", role: "Qwen Max 1T+", temp: 0.3, tokens: 16000 }
  qwen_plus: { model: "qwen-plus", provider: "qwen", fallback: "groq", fallback_model: "qwen/qwen3-32b", role: "Qwen Plus", temp: 0.3, tokens: 12000 }
  qwen_coder_480b: { model: "qwen3-coder-480b-a35b-instruct", provider: "qwen", fallback: "groq", fallback_model: "qwen/qwen3-32b", role: "Qwen Coder 480B", temp: 0.3, tokens: 16000 }
  qwq_reasoning: { model: "qwq-plus", provider: "qwen", fallback: "groq", fallback_model: "qwen/qwen3-32b", role: "QwQ reasoning", temp: 0.2, tokens: 16000 }

workflows:
  develop_feature:
    - { stage: "research", agent: "o3_researcher", prompt: "Research the following task: {description}. Requirements: {requirements}", store: null }
    - { stage: "architecture", agent: "gpt5_flagship", prompt: "Design the architecture for the following research: {research}", store: "architectures" }
    - { stage: "implementation", agent: "cerebras_qwen3_coder", prompt: "Implement the following architecture: {architecture}", store: "implementations" }
    - { stage: "optimization", agent: "qwen_max", prompt: "Optimize the following implementation: {implementation}", store: null }
    - { stage: "reasoning", agent: "qwq_reasoning", prompt: "Reason about the optimized code: {optimization}", store: null }
    - { stage: "prototype", agent: "groq_compound", prompt: "Create a prototype from the reasoning: {reasoning}", store: null }
    - { stage: "production", agent: "llama4_maverick", prompt: "Refine the prototype into production-ready code: {prototype}", store: null }
    - { stage: "review", agent: "gpt41_smart", prompt: "Review the production code: {production}", store: "code_reviews" }
    - { stage: "testing", agent: "qa_engineer", prompt: "Write tests for the production code: {production}", store: "test_strategies" }
    - { stage: "security", agent: "security_auditor", prompt: "Perform a security audit on the production code: {production}", store: "security_findings" }
    - { stage: "documentation", agent: "technical_writer", prompt: "Write documentation for the production code: {production}", store: "documentation" }
    - { stage: "polish", agent: "gpt5_mini", prompt: "Polish the final code: {production}", store: null }
